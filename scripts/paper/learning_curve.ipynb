{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cca5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import pickle\n",
    "from wild_visual_navigation import WVN_ROOT_DIR\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# prev learning_curve\n",
    "base = \"results/ablations/time_adaptation-1000_ge76\"\n",
    "\n",
    "with open(os.path.join(WVN_ROOT_DIR, base, \"time_adaptation-1000_steps.pkl\"), \"rb\") as f:\n",
    "    runs = pickle.load(f)\n",
    "scene = \"forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5548cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_every_n_steps = 1\n",
    "nr_runs = int(np.array([run[\"run\"] for run in runs]).max()) + 1\n",
    "max_step = np.array([run[\"steps\"] for run in runs]).max()\n",
    "max_steps = int(max_step / store_every_n_steps) + 1\n",
    "\n",
    "y_names = [\n",
    "    \"test_auroc_gt_image\",\n",
    "    \"test_auroc_self_image\",\n",
    "    \"test_auroc_anomaly_gt_image\",\n",
    "    \"test_auroc_anomaly_self_image\",\n",
    "    \"test_acc_gt_image\",\n",
    "    \"test_acc_self_image\",\n",
    "    \"test_acc_anomaly_gt_image\",\n",
    "    \"test_acc_anomaly_self_image\",\n",
    "    \"trainer_logged_metrictest_loss_reco\",\n",
    "    \"trainer_logged_metrictest_loss_trav\",\n",
    "    \"trainer_logged_metrictest_loss\",\n",
    "]\n",
    "\n",
    "y = {k: np.zeros((max_steps, nr_runs)) for k in y_names}\n",
    "x_steps = np.arange(0, max_step + store_every_n_steps, store_every_n_steps)\n",
    "\n",
    "model_paths = [\"nan\"] * max_steps\n",
    "for run in runs:\n",
    "    step = int(run[\"steps\"] / store_every_n_steps)\n",
    "    for y_name in y_names:\n",
    "        try:\n",
    "            y[y_name][step, run[\"run\"]] = run[\"results\"][scene][y_name]\n",
    "        except:\n",
    "            pass\n",
    "    model_paths[step] = run[\"model_path\"]\n",
    "\n",
    "y[\"trainer_logged_metrictest_loss_trav\"] *= 16.666666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3ee9c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###################################### AUROC ####################################################\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wild_visual_navigation.visu import paper_colors_rgb_u8, paper_colors_rgba_u8\n",
    "from wild_visual_navigation.visu import paper_colors_rgb_f, paper_colors_rgba_f\n",
    "\n",
    "width_singel_inch, width_double_inch = 88.9 / 25.4, 182.0 / 25.4\n",
    "height_inch = 82 / 25.4\n",
    "scale = 2\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams.update({\"font.size\": 16})\n",
    "\n",
    "fig = plt.figure(figsize=(width_double_inch * scale, height_inch * scale), dpi=300)\n",
    "gs = fig.add_gridspec(nrows=3, ncols=8, left=0.035, right=0.98, top=0.97, wspace=0.9, hspace=0.0)\n",
    "gs = fig.add_gridspec(nrows=3, ncols=8, left=0.035, right=0.98, top=0.97, wspace=0.9, height_ratios=[1.4, 1, 1])\n",
    "ax0 = fig.add_subplot(gs[0, 0:4])\n",
    "ax1 = fig.add_subplot(gs[0, 4:])\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(width_singel_inch*scale, height_inch*scale), dpi=300)\n",
    "ax0.tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "ax1.tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "\n",
    "\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "\n",
    "def plot_auroc(keys, x_steps, y, lim_min, lim_max, ax, y_tags, y_axis_labels, two_axis=False):\n",
    "    x = [x_steps for k in keys]\n",
    "    y_mean = [y[k].mean(axis=1) for k in keys]\n",
    "    y_lower = [y[k].mean(axis=1) - y[k].std(axis=1) for k in keys]\n",
    "    y_upper = [y[k].mean(axis=1) + y[k].std(axis=1) for k in keys]\n",
    "    # not used\n",
    "    ax_ori = ax\n",
    "\n",
    "    for j, (_x, _y, _y_lower, _y_upper, _y_tag) in enumerate(zip(x, y_mean, y_lower, y_upper, y_tags)):\n",
    "        k = [k for k in paper_colors_rgb_f.keys()][j]\n",
    "        if two_axis and j == 1:\n",
    "            ax.plot([0], [0], label=_y_tag, color=paper_colors_rgb_f[k])\n",
    "            ax.legend()\n",
    "\n",
    "            ax.set_ylabel(y_axis_labels[j])\n",
    "\n",
    "        if two_axis and j == 1:\n",
    "            ax = ax.twinx()\n",
    "\n",
    "        ax.plot(_x, _y, label=_y_tag, color=paper_colors_rgb_f[k])\n",
    "        if not (_y_lower is None):\n",
    "            ax.plot(_x, _y_lower, color=paper_colors_rgb_f[k + \"_light\"], alpha=0.1)\n",
    "            ax.plot(_x, _y_upper, color=paper_colors_rgb_f[k + \"_light\"], alpha=0.1)\n",
    "            ax.fill_between(_x, _y_lower, _y_upper, color=paper_colors_rgb_f[k + \"_light\"], alpha=0.2)\n",
    "\n",
    "        if not (two_axis and j == 1):\n",
    "            ax.legend()\n",
    "\n",
    "        ax.tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "\n",
    "    # ax.plot(np.linspace(0, 1, 100), np.linspace(0, 1, 100), linestyle=\"--\", color=\"gray\")\n",
    "\n",
    "    ax_ori.set_xlabel(\"Training Steps\")\n",
    "    ax_ori.spines[\"top\"].set_visible(False)\n",
    "    ax_ori.spines[\"right\"].set_visible(False)\n",
    "    label_x = [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "    ax_ori.set_xticks([0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000])\n",
    "    ax_ori.set_xticklabels(label_x)\n",
    "\n",
    "    if not two_axis:\n",
    "        ax_ori.set_ylabel(y_axis_labels[0])\n",
    "\n",
    "    # plt.xlim(0, 1)\n",
    "    ax_ori.set_ylim(lim_min, lim_max)\n",
    "\n",
    "\n",
    "# plot_auroc(\n",
    "#     [\"test_auroc_gt_image\", \"test_auroc_self_image\"],\n",
    "#     x_steps,\n",
    "#     y,\n",
    "#     0.6,\n",
    "#     1,\n",
    "#     ax0,\n",
    "#     [\"GT AUROC\", \"SELF AUROC\"],\n",
    "#     y_axis_labels=[\"AUROC\"],\n",
    "# )\n",
    "plot_auroc(\n",
    "    [\"trainer_logged_metrictest_loss_reco\", \"trainer_logged_metrictest_loss_trav\"],\n",
    "    x_steps,\n",
    "    y,\n",
    "    None,\n",
    "    None,\n",
    "    ax0,\n",
    "    [\"Reco\", \"Trav\"],\n",
    "    y_axis_labels=[\"Loss\"],\n",
    ")\n",
    "\n",
    "plot_auroc(\n",
    "    [\"test_acc_gt_image\", \"test_acc_self_image\"],\n",
    "    x_steps,\n",
    "    y,\n",
    "    None,\n",
    "    None,\n",
    "    ax1,\n",
    "    [\"GT Acc\", \"SELF Acc\"],\n",
    "    y_axis_labels=[\"Accuracy\", \"Self Acc\"],\n",
    "    two_axis=False,\n",
    ")\n",
    "\n",
    "\n",
    "###################################### Images ####################################################\n",
    "\n",
    "\n",
    "# Setup dataloader\n",
    "from wild_visual_navigation.learning.dataset import get_ablation_module\n",
    "from wild_visual_navigation.learning.utils import load_env\n",
    "from wild_visual_navigation import WVN_ROOT_DIR\n",
    "from wild_visual_navigation.cfg import ExperimentParams\n",
    "\n",
    "from wild_visual_navigation.visu import LearningVisualizer\n",
    "from PIL import Image\n",
    "from wild_visual_navigation.learning.model import get_model\n",
    "from dataclasses import asdict\n",
    "import torch\n",
    "\n",
    "with open(os.path.join(WVN_ROOT_DIR, base, \"experiment_params.pkl\"), \"rb\") as f:\n",
    "    exp = pickle.load(f)\n",
    "exp.ablation_data_module\n",
    "\n",
    "env = load_env()\n",
    "\n",
    "exp.ablation_data_module\n",
    "ablation_data_module = {\n",
    "    \"batch_size\": 1,\n",
    "    \"num_workers\": 0,\n",
    "    \"env\": scene,\n",
    "    \"feature_key\": exp.ablation_data_module.feature_key,\n",
    "    \"test_equals_val\": False,\n",
    "    \"val_equals_test\": False,\n",
    "    \"test_all_datasets\": False,\n",
    "    \"training_data_percentage\": 100,\n",
    "    \"training_in_memory\": False,\n",
    "}\n",
    "train_loader, val_loader, test_loader = get_ablation_module(**ablation_data_module, perugia_root=env[\"perugia_root\"])\n",
    "test_scenes = [a.dataset.env for a in test_loader]\n",
    "test_all_datasets = True\n",
    "\n",
    "\n",
    "def load_model(model_cfg: ExperimentParams.ModelParams, checkpoint_path: str):\n",
    "    model = get_model(asdict(model_cfg))\n",
    "    ckpt = torch.load(checkpoint_path)\n",
    "    ckpt = {\n",
    "        k.replace(\"_model.\", \"\"): v\n",
    "        for k, v in ckpt.items()\n",
    "        if k.find(\"_traversability\") == -1 and k.find(\"threshold\") == -1\n",
    "    }\n",
    "    res = model.load_state_dict(ckpt, strict=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "fontdict = {\n",
    "    \"fontsize\": 16,\n",
    "    \"fontweight\": plt.rcParams[\"axes.titleweight\"],\n",
    "    \"verticalalignment\": \"baseline\",\n",
    "    \"horizontalalignment\": \"center\",\n",
    "}\n",
    "\n",
    "if True:\n",
    "    for l, img_nr in enumerate([20, 32]):\n",
    "        if l == 0:\n",
    "            gs2 = fig.add_gridspec(nrows=3, ncols=8, left=0.06, right=0.97, top=1.0, wspace=0.1, hspace=0.1)\n",
    "            gs2 = fig.add_gridspec(\n",
    "                nrows=3, ncols=8, left=0.03, right=0.98, top=1.0, wspace=0.1, height_ratios=[1.7, 3, 0.1]\n",
    "            )\n",
    "\n",
    "        if l == 1:\n",
    "            gs2 = fig.add_gridspec(nrows=3, ncols=8, left=0.06, right=0.97, top=1.0, wspace=0.1, hspace=0.1)\n",
    "            gs2 = fig.add_gridspec(\n",
    "                nrows=3, ncols=8, left=0.03, right=0.98, top=1.0, bottom=0, wspace=0.1, height_ratios=[1.3, 2.15, 2.0]\n",
    "            )\n",
    "\n",
    "        thresholds = []\n",
    "        models = [0, 99, 249, 499, 999]\n",
    "        for j, training_step in enumerate(models):\n",
    "            model = load_model(exp.model, model_paths[training_step])\n",
    "            model.to(\"cuda\")\n",
    "            graph = test_loader[0].dataset[img_nr]\n",
    "            pred = model(graph)\n",
    "            visualizer = LearningVisualizer()\n",
    "            img = graph.img\n",
    "            seg = graph.seg\n",
    "            res = visualizer.plot_detectron(img[0], graph.label[0].type(torch.long), not_log=True, max_seg=2)\n",
    "            center = graph.center\n",
    "\n",
    "            threshold = torch.load(model_paths[training_step])[\"threshold\"].item()\n",
    "            thresholds.append(threshold)\n",
    "            traversability = pred[:, 0]\n",
    "            m = traversability < threshold\n",
    "            # Scale untraversable\n",
    "            traversability[m] *= 0.5 / threshold\n",
    "            # Scale traversable\n",
    "            traversability[~m] -= threshold\n",
    "            traversability[~m] *= 0.5 / (1 - threshold)\n",
    "            traversability[~m] += 0.5\n",
    "            traversability = traversability.clip(0, 1)\n",
    "\n",
    "            buffer_traversability = graph.seg.clone().type(torch.float32).flatten()\n",
    "            BS, H, W = graph.seg.shape\n",
    "            seg_pixel_index = (graph.seg).flatten()\n",
    "            buffer_traversability = traversability[seg_pixel_index].reshape(BS, H, W)\n",
    "            res_pred = visualizer.plot_detectron_classification(img[0], buffer_traversability, not_log=True)\n",
    "\n",
    "            # res_pred = visualizer.plot_traversability_graph_on_seg(\n",
    "            #    traversability, seg[0], graph, center, img[0], not_log=True, colorize_invalid_centers=True\n",
    "            # )\n",
    "\n",
    "            ax = fig.add_subplot(gs2[1 + l, j + 2])\n",
    "            ax.imshow(res_pred)\n",
    "            ax.axis(\"off\")\n",
    "            step = int((training_step + 1) * 1)\n",
    "            if l == 1:\n",
    "                ax.set_title(f\"Step-{step}\", fontdict=fontdict, loc=\"center\", y=0, pad=-16)\n",
    "\n",
    "        # graph.seg[0]\n",
    "        res_img = visualizer.plot_detectron(\n",
    "            img[0],\n",
    "            graph.label[0].type(torch.long) * 99,\n",
    "            not_log=True,\n",
    "            max_seg=100,\n",
    "            colormap=\"RdYlBu\",\n",
    "            boundary_seg=None,\n",
    "            alpha=0,\n",
    "        )\n",
    "        res_gt = visualizer.plot_detectron(\n",
    "            img[0],\n",
    "            graph.label[0].type(torch.long) * 99,\n",
    "            not_log=True,\n",
    "            max_seg=100,\n",
    "            colormap=\"RdYlBu\",\n",
    "            boundary_seg=None,\n",
    "        )\n",
    "        res_prop = visualizer.plot_traversability_graph_on_seg(\n",
    "            graph.y, seg[0], graph, center, img[0], not_log=True, colorize_invalid_centers=True\n",
    "        )\n",
    "\n",
    "        ax0 = fig.add_subplot(gs2[1 + l, 0])\n",
    "        ax1 = fig.add_subplot(gs2[1 + l, 1])\n",
    "        ax7 = fig.add_subplot(gs2[1 + l, 7])\n",
    "\n",
    "        res = ax0.text(-110, 370, s=f\"Example {l+1}\", fontsize=16, rotation=90)\n",
    "\n",
    "        if l == 1:\n",
    "            ax0.set_title(\"Image\", fontdict=fontdict, loc=\"center\", y=0, pad=-16)\n",
    "            ax1.set_title(\"Supervision\", fontdict=fontdict, loc=\"center\", y=0, pad=-16)\n",
    "            ax7.set_title(\"Label\", fontdict=fontdict, loc=\"center\", y=0, pad=-16)\n",
    "\n",
    "        ax0.axis(\"off\")\n",
    "        ax1.axis(\"off\")\n",
    "        ax7.axis(\"off\")\n",
    "\n",
    "        ax0.imshow(res_img)\n",
    "        ax1.imshow(res_prop)\n",
    "        ax7.imshow(res_gt)\n",
    "\n",
    "fig.set_tight_layout(False)\n",
    "fig.savefig(\"/tmp/img.png\", dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wvn",
   "language": "python",
   "name": "wvn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
