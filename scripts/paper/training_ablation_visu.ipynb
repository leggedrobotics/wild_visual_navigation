{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe70020",
   "metadata": {},
   "source": [
    "# Load run data and convert to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b50d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "\n",
    "from wild_visual_navigation import WVN_ROOT_DIR\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "folder, model_name = \"confidence_fn\", False\n",
    "folder, model_name = \"lr\", False\n",
    "folder, model_name = \"feature\", False\n",
    "folder, model_name = \"loss\", False\n",
    "folder, model_name = \"network\", False\n",
    "\n",
    "\n",
    "\n",
    "folder, model_name = \"threshold\", False\n",
    "folder, model_name = \"classicial_learning\", True\n",
    "folder, model_name = \"anomaly_detection_only\", False\n",
    "# folder, model_name = \"debug\", False\n",
    "# p = os.path.join(WVN_ROOT_DIR, f\"scripts/ablations/{folder}_ablation/{folder}_ablation_test_results.pkl\")\n",
    "ws = \"_\" + os.environ[\"ENV_WORKSTATION_NAME\"]\n",
    "p = os.path.join(WVN_ROOT_DIR, f\"results/ablations/{folder}_ablation{ws}/{folder}_ablation_test_results.pkl\")\n",
    "with open(p, \"rb\") as f:\n",
    "    res = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55ba28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "data = {\n",
    "    \"run_nr\": [],\n",
    "    \"cfg_name\": [],\n",
    "    \"train_scene\": [],\n",
    "    \"test_scene\": [],\n",
    "}\n",
    "\n",
    "for train_scene_name, scene_data in res.items():\n",
    "    for config_path, config_data in scene_data.items():\n",
    "        if model_name:\n",
    "            name = config_path\n",
    "        else:\n",
    "            # its a path\n",
    "            name = config_path.split(\"/\")[-1][:-5]\n",
    "        for run_nr, run_data in config_data.items():\n",
    "            for test_scene_name, test_scene_data in run_data.items():\n",
    "                data[\"cfg_name\"].append(name)\n",
    "                data[\"run_nr\"].append(run_nr)\n",
    "                data[\"train_scene\"].append(train_scene_name)\n",
    "                data[\"test_scene\"].append(test_scene_name)\n",
    "                for k in test_scene_data.keys():\n",
    "                    if type(test_scene_data[k]) is float:\n",
    "                        try:\n",
    "                            data[k].append(test_scene_data[k])\n",
    "                        except:\n",
    "                            data[k] = [test_scene_data[k]]\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "data_acc = {\n",
    "    \"cfg_name\": [],\n",
    "    \"train_scene\": [],\n",
    "    \"test_scene\": [],\n",
    "}\n",
    "\n",
    "data_auroc = {\n",
    "    \"cfg_name\": [],\n",
    "    \"train_scene\": [],\n",
    "    \"test_scene\": [],\n",
    "}\n",
    "keys = []\n",
    "for i in range(len(df)):\n",
    "    n = data[\"cfg_name\"][i]\n",
    "    tr = data[\"train_scene\"][i]\n",
    "    te = data[\"test_scene\"][i]\n",
    "\n",
    "    a = df[(df[\"train_scene\"] == tr) * (df[\"test_scene\"] == te) * (df[\"cfg_name\"] == n)]\n",
    "    k = n + tr + te\n",
    "    if k in keys:\n",
    "        continue\n",
    "    keys.append(k)\n",
    "\n",
    "    data_auroc[\"cfg_name\"].append(n)\n",
    "    data_auroc[\"train_scene\"].append(tr)\n",
    "    data_auroc[\"test_scene\"].append(te)\n",
    "\n",
    "    data_acc[\"cfg_name\"].append(n)\n",
    "    data_acc[\"train_scene\"].append(tr)\n",
    "    data_acc[\"test_scene\"].append(te)\n",
    "\n",
    "    for k in a.keys():\n",
    "\n",
    "        if k.find(\"auroc\") != -1:\n",
    "            try:\n",
    "                data_auroc[k + \"_std\"].append(a[k].std())\n",
    "                data_auroc[k + \"_m\"].append(a[k].mean())\n",
    "            except:\n",
    "                data_auroc[k + \"_std\"] = [a[k].std()]\n",
    "                data_auroc[k + \"_m\"] = [a[k].mean()]\n",
    "        if k.find(\"acc\") != -1:\n",
    "            try:\n",
    "                data_acc[k + \"_std\"].append(a[k].std())\n",
    "                data_acc[k + \"_m\"].append(a[k].mean())\n",
    "            except:\n",
    "                data_acc[k + \"_std\"] = [a[k].std()]\n",
    "                data_acc[k + \"_m\"] = [a[k].mean()]\n",
    "df_auroc = pd.DataFrame.from_dict(data_auroc)\n",
    "df_auroc = df_auroc.round(decimals=4)\n",
    "df_auroc[df_auroc.select_dtypes(include=[\"number\"]).columns] = (\n",
    "    df_auroc[df_auroc.select_dtypes(include=[\"number\"]).columns] * 100\n",
    ")\n",
    "\n",
    "df_acc = pd.DataFrame.from_dict(data_acc)\n",
    "df_acc = df_acc.round(decimals=4)\n",
    "df_acc[df_acc.select_dtypes(include=[\"number\"]).columns] = (\n",
    "    df_acc[df_acc.select_dtypes(include=[\"number\"]).columns] * 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08841994",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc = df_acc.sort_values(\"test_acc_gt_image_m\", ascending=False)\n",
    "scene = \"hilly\"\n",
    "df_acc[(df_acc[\"train_scene\"].str.find(scene) != -1)]  # * (df_acc[\"test_scene\"].str.find(scene) != -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a22059",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc = df_acc.sort_values(\"test_acc_gt_image_m\", ascending=False)\n",
    "scene = \"forest\"\n",
    "df_acc[(df_acc[\"train_scene\"].str.find(scene) != -1)]  # (df[\"test_scene\"].str.find(scene) != -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cc7cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc = df_acc.sort_values(\"test_acc_gt_image_m\", ascending=False)\n",
    "scene = \"grassland\"\n",
    "df_acc[(df_acc[\"train_scene\"].str.find(scene) != -1)]  # (df[\"test_scene\"].str.find(scene) != -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabe160e",
   "metadata": {},
   "source": [
    "# Time Adaptation and Data Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd542ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from wild_visual_navigation import WVN_ROOT_DIR\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "with open(os.path.join(WVN_ROOT_DIR, f\"results/ablations/time_adaptation{ws}/time_adaptation_steps.pkl\"), \"rb\") as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "steps_div = 100\n",
    "nr_training_data, nr_steps, nr_runs = 10, int(10000 / steps_div), 1\n",
    "\n",
    "auroc_gt = {}\n",
    "auroc_gt[\"forest\"] = np.zeros((nr_training_data, nr_steps, nr_runs))\n",
    "auroc_gt[\"grassland\"] = np.zeros((nr_training_data, nr_steps, nr_runs))\n",
    "auroc_gt[\"hilly\"] = np.zeros((nr_training_data, nr_steps, nr_runs))\n",
    "auroc_prop = {}\n",
    "auroc_prop[\"forest\"] = np.zeros((nr_training_data, nr_steps, nr_runs))\n",
    "auroc_prop[\"grassland\"] = np.zeros((nr_training_data, nr_steps, nr_runs))\n",
    "auroc_prop[\"hilly\"] = np.zeros((nr_training_data, nr_steps, nr_runs))\n",
    "\n",
    "\n",
    "for data in res:\n",
    "    percentage, steps, run = data[\"percentage\"], data[\"steps\"], data[\"run\"]\n",
    "\n",
    "    da = [v for v in data[\"results\"].values()][0]\n",
    "\n",
    "    auroc_gt[data[\"scene\"]][int(percentage / 10) - 1, int(steps / steps_div), run] = da[\"test_acc_gt_image\"]\n",
    "    auroc_prop[data[\"scene\"]][int(percentage / 10) - 1, int(steps / steps_div), run] = da[\"test_acc_self_image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df98e062",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot(title, data):\n",
    "    width_half_inch, width_double_inch = 88.9 / 25.4, 182.0 / 25.4\n",
    "    height_inch = 50 / 25.4\n",
    "    scale = 2\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(width_half_inch * scale, height_inch * scale), dpi=300)\n",
    "    fig.set_tight_layout(True)\n",
    "    plt.rcParams.update({\"font.size\": 16})\n",
    "    ax[1].tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "\n",
    "    # Plot Matrix\n",
    "    label_y = [str(k) for k in range(10, 101, 10)]\n",
    "    label_x = [str(200)] + [str(int(j / 1000)) + \"k\" for j in range(300, data.shape[1] * 102, 100)]\n",
    "\n",
    "    im = ax[1].imshow(data, cmap=sns.color_palette(\"RdYlBu\", as_cmap=True))\n",
    "    # ele = [0] + list(np.arange(8, 100, 10))\n",
    "\n",
    "    # ax[1].set_xticks(ele)\n",
    "    # ax[1].set_yticks(np.arange(len(label_y))[::2])\n",
    "\n",
    "    # index = np.array([0] + list(np.arange(8, 100, 10)))\n",
    "    # ax[1].set_xticklabels(np.array(label_x)[index])\n",
    "    # ax[1].set_yticklabels(label_y[::2])\n",
    "\n",
    "    ax[1].invert_yaxis()\n",
    "    # ax[1].set_xlabel(\"Training Steps\")\n",
    "    # ax[1].set_ylabel(\"Data Percentage\")\n",
    "\n",
    "    plt.setp(ax[1].get_xticklabels(), rotation=0, ha=\"center\", rotation_mode=\"anchor\")\n",
    "    ax[1].set_aspect(3.5)\n",
    "\n",
    "    # Plot color bar\n",
    "    nr = 100\n",
    "    bar = np.arange(0, nr)[None]\n",
    "    im = ax[0].imshow(bar, cmap=sns.color_palette(\"RdYlBu\", as_cmap=True))\n",
    "    ax[0].set_aspect(2)\n",
    "    ax[0].set_xticks(np.array([0, nr - 1]))\n",
    "    ax[0].set_yticks(np.array([]))\n",
    "    ax[0].set_xticklabels(np.array([round(data.min() * 100, 1), round(data.max() * 100, 1)]))\n",
    "    ax[0].set_yticklabels([])\n",
    "\n",
    "    ax[1].tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "    ax[1].tick_params(axis=\"both\", which=\"minor\", labelsize=12)\n",
    "    ax[0].tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "    ax[0].tick_params(axis=\"both\", which=\"minor\", labelsize=12)\n",
    "\n",
    "    ax[0].set_xlabel(\"ACC in percentage\")\n",
    "    ax[0].xaxis.set_label_coords(0.5, -1)\n",
    "\n",
    "    plt.subplots_adjust(hspace=-0.5)\n",
    "    plt.show()\n",
    "    fig.savefig(\"/tmp/img.png\", dpi=300)\n",
    "\n",
    "\n",
    "plot(\"Time/Data-Adaptation ACC GT\", auroc_prop[\"forest\"][:, 2:].mean(axis=2))\n",
    "plot(\"Time/Data-Adaptation ACC GT\", auroc_gt[\"forest\"][:, 2:].mean(axis=2))\n",
    "# plot(\"Time/Data-Adaptation ACC GT\", auroc_prop[\"hilly\"][:, 2:].mean(axis=2))\n",
    "# plot(\"Time/Data-Adaptation ACC GT\", auroc_gt[\"hilly\"][:, 2:].mean(axis=2))\n",
    "# plot(\"Time/Data-Adaptation AUCROC GT\", auroc_prop[\"grassland\"][:, 10:].mean(axis=2))\n",
    "# plot(\"Time/Data-Adaptation AUCROC GT\", auroc_gt[\"grassland\"][:, 10:].mean(axis=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wvn",
   "language": "python",
   "name": "wvn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
